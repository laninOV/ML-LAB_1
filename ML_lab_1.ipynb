{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Студент       | Ланин Олег                    | \n",
    "|-----------|------------------------------------|\n",
    "| Группа  | М8О-301Б-19  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "\n",
    "1) Реализовать следующие алгоритмы машинного обучения: Linear/ Logistic Regression, SVM, KNN, Naive Bayes в отдельных классах \n",
    "2)  Данные классы должны наследоваться от BaseEstimator и  ClassifierMixin, иметь методы fit и predict (подробнее: https://scikit-learn.org/stable/developers/develop.html )\n",
    "3) Вы должны организовать весь процесс предобработки, обучения и тестирования с помощью Pipeline (подробнее: https://scikit-learn.org/stable/modules/compose.html)\n",
    "4) Вы должны настроить гиперпараметры моделей с помощью кросс валидации (GridSearchCV,RandomSearchCV, подробнее здесь: https://scikit-learn.org/stable/modules/grid_search.html), вывести и сохранить эти гиперпараметры в файл, вместе с обученными моделями\n",
    "5) Проделать аналогично с коробочными решениями\n",
    "6) Для каждой модели получить оценки метрик:Confusion Matrix,  Accuracy, Recall, Precision, ROC_AUC curve (подробнее: Hands on machine learning with python and scikit learn chapter 3, mlcourse.ai, https://ml-handbook.ru/chapters/model_evaluation/intro)\n",
    "7) Проанализировать полученные результаты и сделать выводы о применимости моделей\n",
    "8) Загрузить полученные гиперпараметры модели и обученные модели в формате pickle  на гит вместе с jupyter notebook ваших экспериментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_train, df_test]:\n",
    "    mean = df['Age'].mean()\n",
    "    std = df['Age'].std()\n",
    "    number_of_nulls = df['Age'].isnull().sum()\n",
    "    random_ages = np.random.randint(mean - std, mean + std, size=number_of_nulls)\n",
    "\n",
    "    new_ages = df['Age'].copy()\n",
    "    new_ages[np.isnan(new_ages)] = random_ages\n",
    "    df['Age'] = new_ages\n",
    "\n",
    "for df in [df_train, df_test]:\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')\n",
    "\n",
    "df_test = df_test[df_test['Fare'].notnull()]\n",
    "\n",
    "df_train = df_train.drop(columns=['Name', 'PassengerId', 'Ticket', 'Cabin'])\n",
    "df_test = df_test.drop(columns=['Name', 'PassengerId', 'Ticket', 'Cabin'])\n",
    "\n",
    "df_train['Relatives'] = df_train['Parch'] + df_train['SibSp']\n",
    "df_test['Relatives'] = df_test['Parch'] + df_test['SibSp']\n",
    "df_train = df_train.drop(columns=['SibSp', 'Parch'])\n",
    "df_test = df_test.drop(columns=['SibSp', 'Parch'])\n",
    "\n",
    "genders = {'male': 0, 'female': 1}\n",
    "ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
    "for df in [df_train, df_test]:\n",
    "    df['Sex'] = df['Sex'].map(genders)\n",
    "    df['Embarked'] = df['Embarked'].map(ports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Relatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age     Fare  Embarked  Survived  Relatives\n",
       "0       3    0  34.5   7.8292         2         0          0\n",
       "1       3    1  47.0   7.0000         0         1          1\n",
       "2       2    0  62.0   9.6875         2         0          0\n",
       "3       3    0  27.0   8.6625         0         0          0\n",
       "4       3    1  22.0  12.2875         0         1          2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train.drop(columns=['Survived']).to_numpy()\n",
    "Y_train = df_train['Survived'].to_numpy()\n",
    "\n",
    "X_test = df_test.drop(columns=['Survived']).to_numpy()\n",
    "Y_test = df_test['Survived'].to_numpy()\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPTci8ZHFOt5"
   },
   "source": [
    "Вспомогательные функции для анализа результатов классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "jCsiVDAQFOuH"
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(y_pred, y_test):\n",
    "    matrix = pd.DataFrame({'actual_1' : [0, 0], 'actual_0': [0, 0]})\n",
    "    matrix.index = ['predicted_1', 'predicted_0']\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == 1 and y_test[i] == 1:\n",
    "            matrix.loc['predicted_1', 'actual_1'] += 1\n",
    "        elif y_pred[i] == 1 and y_test[i] == 0:\n",
    "            matrix.loc['predicted_1', 'actual_0'] += 1\n",
    "        elif y_pred[i] == 0 and y_test[i] == 1:\n",
    "            matrix.loc['predicted_0', 'actual_1'] += 1\n",
    "        else:\n",
    "            matrix.loc['predicted_0', 'actual_0'] += 1\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def metrics(matrix):\n",
    "    TP = matrix.loc['predicted_1', 'actual_1']\n",
    "    FP = matrix.loc['predicted_1', 'actual_0']\n",
    "    FN = matrix.loc['predicted_0', 'actual_1']\n",
    "    TN = matrix.loc['predicted_0', 'actual_0']\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "\n",
    "    return accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MGC-PFQFOuI"
   },
   "source": [
    "# Построение моделей\n",
    "## 1. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "id": "CDLC9RSVFOuI"
   },
   "outputs": [],
   "source": [
    "class WeightedKNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, K=3):\n",
    "        self.K = K\n",
    "    \n",
    "    def fit(self, X_train, Y_train):\n",
    "        self.X_train = X_train.to_numpy()\n",
    "        self.Y_train = Y_train.to_numpy()\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_test = X_test.to_numpy()\n",
    "\n",
    "        # Нормализуем данные в каждом столбце\n",
    "        self.X_train = np.apply_along_axis(lambda x: (x-x.mean())/ x.std(), 0, self.X_train)\n",
    "        X_test = np.apply_along_axis(lambda x: (x-x.mean())/ x.std(), 0, X_test)\n",
    "\n",
    "        Y_pred = []\n",
    "        \n",
    "        for p in X_test:        \n",
    "            distances = list()\n",
    "            # Считаем расстояния от данной точки до всех остальных\n",
    "            for row_idx, row in enumerate(self.X_train):\n",
    "                distance = 0\n",
    "                for feature_idx in range(len(p)):\n",
    "                    distance += (p[feature_idx] - row[feature_idx])**2\n",
    "\n",
    "                # Добавляем в список пару расстояние-класс\n",
    "                distances.append([math.sqrt(distance), Y_train[row_idx]])\n",
    "\n",
    "            # Находим К ближайших точек\n",
    "            k_closest_points = sorted(distances, key=lambda x: x[0])[:self.K]\n",
    "\n",
    "            # Находим числа, обратные к каждому расстоянию\n",
    "            inverse_distances = list()\n",
    "            for dist in k_closest_points:\n",
    "                inverse_distances.append(1/dist[0])\n",
    "            \n",
    "            # Находим сумму этих обратных чисел\n",
    "            sum_of_inverses = sum(inverse_distances)\n",
    "            \n",
    "            # Находим вес для каждой точки + соответствующий ей класс\n",
    "            weights = [[inverse/sum_of_inverses, k_closest_points[idx][1]] for idx, inverse in enumerate(inverse_distances)]\n",
    "\n",
    "            # Считаем вероятности для каждого класса\n",
    "            probabilities = {c : 0 for c in Y_train.unique()}\n",
    "            for elem in weights:\n",
    "                probabilities[elem[1]] += elem[0]\n",
    "            \n",
    "            # Возвращаем класс с максимальной вероятностью\n",
    "            Y_pred.append(max(probabilities, key=probabilities.get))\n",
    "\n",
    "        return np.array(Y_pred)\n",
    "\n",
    "    def accuracy_score(self, Y_test, Y_pred):\n",
    "\t    return sum(np.array(Y_pred) == np.array(Y_test)) / len(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4YFlBP2FOuJ",
    "outputId": "a6647f43-8adb-459e-961e-5e3f443ed793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for weighted KNN with K = 7 : 0.8800959232613909\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "for i in range(2, 15):\n",
    "    my_knn = WeightedKNNClassifier(K=i)\n",
    "    my_knn.fit(X_train, Y_train)\n",
    "    Y_pred = my_knn.predict(X_test)\n",
    "    print(f\"Accuracy for weighted KNN with K = {i} : {my_knn.accuracy_score(Y_test, Y_pred)}\")\n",
    "'''\n",
    "# Из данного теста мы выяснили, что оптимальный K = 7\n",
    "\n",
    "my_knn = WeightedKNNClassifier(K=7)\n",
    "my_knn.fit(X_train, Y_train)\n",
    "Y_pred = my_knn.predict(X_test)\n",
    "print(f\"Accuracy for weighted KNN with K = 7 : {my_knn.accuracy_score(Y_test, Y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "id": "wfUV2uhOFOuJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy for sklearn's KNN: 0.6714628297362111\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in range(2, 100):\n",
    "    knn = KNeighborsClassifier(n_neighbors = i)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    Y_pred = knn.predict(X_test)\n",
    "    scores.append((Y_test == Y_pred).sum() / len(Y_test))\n",
    "\n",
    "print(f'Best accuracy for sklearn\\'s KNN: {max(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjv9YXFY1gMm",
    "outputId": "932d2b4f-c601-4383-b1d5-dac9abe1186b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy for sklearn's KNN with normalized data: 0.9760191846522782\n"
     ]
    }
   ],
   "source": [
    "# Same with normalized data\n",
    "\n",
    "X_train_normalized = X_train.apply(lambda x: (x-x.mean())/ x.std(), axis=0)\n",
    "X_test_normalized = X_test.apply(lambda x: (x-x.mean())/ x.std(), axis=0)\n",
    "\n",
    "scores = []\n",
    "for i in range(2, 100):\n",
    "    knn = KNeighborsClassifier(n_neighbors = i)\n",
    "    knn.fit(X_train_normalized, Y_train)\n",
    "    Y_pred = knn.predict(X_test_normalized)\n",
    "    scores.append((Y_test == Y_pred).sum() / len(Y_test))\n",
    "\n",
    "print(f'Best accuracy for sklearn\\'s KNN with normalized data: {max(scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_probabilities(self, class_idx: int, x: np.array) -> np.array:\n",
    "        # Считаем вероятность как значение функции плотности нормального распределения в точке x=(p_1,..,p_n)  \n",
    "    \n",
    "        # Массив матожиданий и дисперсий для каждого признака при данном классе\n",
    "        mean = self.mean_cond_class[class_idx]\n",
    "        var = self.var_cond_class[class_idx]\n",
    "\n",
    "        # Считаем вероятность для каждого признака, используя плотность вероятности нормального распределения\n",
    "        exponent = np.exp((-1/2) * ((x-mean)**2) / (2 * var))\n",
    "        probabilities = exponent / np.sqrt(2 * np.pi * var)\n",
    "        return probabilities\n",
    "\n",
    "    # Найдем P(class|p_1,..,p_n)\n",
    "    def get_posterior(self, x: np.array) -> int:\n",
    "        posteriors = []\n",
    "        for class_idx in range(self.num_of_classes):\n",
    "            prior = np.log(self.prior[class_idx])\n",
    "            # Условная вероятность получить такие значения признаков для этого класса\n",
    "            conditional = np.sum(np.log(self.get_probabilities(class_idx, x)))\n",
    "            posterior = prior + conditional\n",
    "            posteriors.append(posterior)\n",
    "        # Возвращаем класс, для которого такая вероятность максимальна\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "\n",
    "    def fit(self, X_train, Y_train):\n",
    "        self.classes = np.unique(Y_test)\n",
    "        self.num_of_classes = len(self.classes)\n",
    "        \n",
    "        # Посчитаем выборочные средние и дисперсии для каждого признака в зависимости от класса\n",
    "        self.mean_cond_class = X_train.groupby(Y_train).apply(np.mean).to_numpy()\n",
    "        self.var_cond_class = X_train.groupby(Y_train).apply(np.var).to_numpy()\n",
    "\n",
    "        # Считаем для каждого класса, сколько наблюдений принадлежит этому классу\n",
    "        self.prior = X_train.groupby(Y_train).apply(lambda col: len(col))\n",
    "        # Находим оценку вероятности того, что случайное наблюдение принадлежит этому классу\n",
    "        # путём деления результатов на общее количество наблюдений\n",
    "        self.prior = np.array(self.prior / len(Y_train))\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        Y_pred = [self.get_posterior(f) for f in X_test.to_numpy()]\n",
    "        return Y_pred\n",
    "    \n",
    "    def accuracy_score(self, Y_test, Y_pred):\n",
    "        return sum(Y_pred == Y_test) / len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "id": "s4sMzVGjFOuK",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of custom Naive Bayes: 0.8033573141486811\n"
     ]
    }
   ],
   "source": [
    "nbc = NaiveBayesClassifier()\n",
    "nbc.fit(X_train, Y_train)\n",
    "Y_pred = nbc.predict(X_test)\n",
    "print(f'Accuracy of custom Naive Bayes: {nbc.accuracy_score(Y_test, Y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "UJkVYHGyFOuK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sklearn Naive Bayes: 0.797979797979798\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB() \n",
    "gaussian.fit(X_train, Y_train) \n",
    "Y_pred = gaussian.predict(X_test)  \n",
    "print(f'Accuracy of sklearn Naive Bayes: {gaussian.score(X_train, Y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_Logistic_Regression(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, learning_rate, n_iterations):        \n",
    "        self.learning_rate = learning_rate        \n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.X = X.copy()\n",
    "        self.Y = Y.copy()\n",
    "        n_samples, n_features = X.shape     \n",
    "        self.W = np.zeros(n_features)        \n",
    "        self.b = 0\n",
    "\n",
    "        # обновление весов с помощью градиентного спуска\n",
    "        for _ in range(self.n_iterations):\n",
    "            linear_model = np.dot(self.X, self.W) + self.b          \n",
    "            y_predicted = 1 / (1 + np.exp(-linear_model))\n",
    "\n",
    "            dW = (1 / n_samples) * np.dot(X.T, y_predicted - Y)\n",
    "            db = (1 / n_samples) * np.sum(y_predicted - Y)\n",
    "            self.W -= self.learning_rate * dW    \n",
    "            self.b -= self.learning_rate * db  \n",
    "\n",
    "    def predict(self, X):\n",
    "        S = np.array(1 / (1 + np.exp(-(np.dot(X, self.W) + self.b))))\n",
    "        # если сигмойд получается больше, чем 0.5, то предсказываем класс 1\n",
    "        return np.where(S >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate = 0.1, iterations = 500, train accuracy = 0.691358024691358, test accuracy = 0.6690647482014388\n",
      "Learning rate = 0.1, iterations = 1000, train accuracy = 0.6621773288439955, test accuracy = 0.657074340527578\n",
      "Learning rate = 0.1, iterations = 1500, train accuracy = 0.6161616161616161, test accuracy = 0.6354916067146283\n",
      "Learning rate = 0.01, iterations = 1000, train accuracy = 0.6352413019079686, test accuracy = 0.657074340527578\n",
      "Learning rate = 0.01, iterations = 2000, train accuracy = 0.6531986531986532, test accuracy = 0.6618705035971223\n",
      "Learning rate = 0.01, iterations = 5000, train accuracy = 0.7216610549943884, test accuracy = 0.762589928057554\n",
      "Learning rate = 0.01, iterations = 10000, train accuracy = 0.7530864197530864, test accuracy = 0.8465227817745803\n",
      "Learning rate = 0.001, iterations = 1000, train accuracy = 0.6879910213243546, test accuracy = 0.6498800959232613\n",
      "Learning rate = 0.001, iterations = 3000, train accuracy = 0.7014590347923682, test accuracy = 0.6738609112709832\n",
      "Learning rate = 0.001, iterations = 5000, train accuracy = 0.712682379349046, test accuracy = 0.6930455635491607\n",
      "Learning rate = 0.001, iterations = 10000, train accuracy = 0.7609427609427609, test accuracy = 0.7769784172661871\n",
      "Learning rate = 0.001, iterations = 15000, train accuracy = 0.7957351290684624, test accuracy = 0.8441247002398081\n",
      "Learning rate = 0.0001, iterations = 2000, train accuracy = 0.6778900112233446, test accuracy = 0.657074340527578\n",
      "Learning rate = 0.0001, iterations = 5000, train accuracy = 0.6857463524130191, test accuracy = 0.657074340527578\n",
      "Learning rate = 0.0001, iterations = 10000, train accuracy = 0.6879910213243546, test accuracy = 0.6498800959232613\n",
      "Learning rate = 0.0001, iterations = 15000, train accuracy = 0.6924803591470258, test accuracy = 0.6522781774580336\n",
      "Learning rate = 0.0001, iterations = 20000, train accuracy = 0.6936026936026936, test accuracy = 0.6666666666666666\n",
      "Learning rate = 0.0001, iterations = 50000, train accuracy = 0.712682379349046, test accuracy = 0.6930455635491607\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = [\n",
    "(0.1, 500), \n",
    "(0.1, 1000), \n",
    "(0.1, 1500),\n",
    "(0.01, 1000),\n",
    "(0.01, 2000),\n",
    "(0.01, 5000),\n",
    "(0.01, 10000),\n",
    "(0.001, 1000),\n",
    "(0.001, 3000),\n",
    "(0.001, 5000),\n",
    "(0.001, 10000),\n",
    "(0.001, 15000),\n",
    "(0.0001, 2000),\n",
    "(0.0001, 5000),\n",
    "(0.0001, 10000),\n",
    "(0.0001, 15000),\n",
    "(0.0001, 20000),\n",
    "(0.0001, 50000)\n",
    "]\n",
    "\n",
    "for pair in hyperparameters:\n",
    "    lr, iters = pair\n",
    "    my_log_regr = my_Logistic_Regression(learning_rate=lr, n_iterations=iters)\n",
    "    my_log_regr.fit(X_train, Y_train)\n",
    "    Y_pred_test = my_log_regr.predict(X_test)\n",
    "    Y_pred_train = my_log_regr.predict(X_train)\n",
    "    print(f'Learning rate = {lr}, iterations = {iters}, train accuracy = {np.mean(Y_train == Y_pred_train)}, test accuracy = {np.mean(Y_test == Y_pred_test)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylogit = my_Logistic_Regression(learning_rate=0.001, n_iterations=15000)\n",
    "mylogit.fit(X_train, Y_train)\n",
    "Y_pred = mylogit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_1</th>\n",
       "      <th>actual_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted_1</th>\n",
       "      <td>103</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_0</th>\n",
       "      <td>49</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual_1  actual_0\n",
       "predicted_1       103        16\n",
       "predicted_0        49       249"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8441247002398081\n",
      "Precision: 0.865546218487395\n",
      "Recall: 0.6776315789473685\n"
     ]
    }
   ],
   "source": [
    "metrics_mylogreg = metrics(confusion_matrix(Y_pred, Y_test))\n",
    "print(f'Accuracy: {metrics_mylogreg[0]}\\nPrecision: {metrics_mylogreg[1]}\\nRecall: {metrics_mylogreg[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили довольно низкий recall. Это значит (и видно из таблицы), что модель предсказала малую долю выживших людей, то есть много выживших она определила как погибших.\n",
    "\n",
    "Теперь посмотрим на модель из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression().fit(X_train, Y_train)\n",
    "Y_pred = logreg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_1</th>\n",
       "      <th>actual_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted_1</th>\n",
       "      <td>140</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_0</th>\n",
       "      <td>12</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual_1  actual_0\n",
       "predicted_1       140        16\n",
       "predicted_0        12       249"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9328537170263789\n",
      "Precision: 0.8974358974358975\n",
      "Recall: 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "metrics_sklogreg = metrics(confusion_matrix(Y_pred, Y_test))\n",
    "print(f'Accuracy: {metrics_sklogreg[0]}\\nPrecision: {metrics_sklogreg[1]}\\nRecall: {metrics_sklogreg[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что модель логистический регрессии из sklearn справилась немного лучше, чем реализованная. Причем recall получился немного выше, чем precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_SVM(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, learning_rate=0.01, lambda_param=0.01, n_iters=10000):\n",
    "        self.lr = learning_rate\n",
    "        self.lambda_param = lambda_param\n",
    "        self.n_iters = n_iters\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # переименовываем лейблы в -1 и 1\n",
    "        y_ = np.where(y <= 0, -1, 1)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        self.W = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "\n",
    "        # процесс обучения (настройка весов и смещения)\n",
    "        for _ in range(self.n_iters):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                condition = y_[idx] * ((x_i @ self.W) - self.b) >= 1\n",
    "                if condition:\n",
    "                    self.W -= self.lr * (2 * self.lambda_param * self.W)\n",
    "                else:\n",
    "                    self.W -= self.lr * (2 * self.lambda_param * self.W - np.dot(x_i,y_[idx]))\n",
    "                    self.b -= self.lr * y_[idx]\n",
    "\n",
    "    def predict(self, X):\n",
    "        res = np.dot(X, self.W) - self.b\n",
    "        # предсказываем класс в зависимости от знака\n",
    "        return np.where(res >= 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate = 0.01, lambda = 0.01, iterations = 2000, train accuracy = 0.7441077441077442, test accuracy = 0.7146282973621103\n",
      "Learning rate = 0.01, lambda = 0.01, iterations = 5000, train accuracy = 0.7227833894500562, test accuracy = 0.7122302158273381\n",
      "Learning rate = 0.001, lambda = 0.01, iterations = 1000, train accuracy = 0.7777777777777778, test accuracy = 0.8537170263788969\n",
      "Learning rate = 0.001, lambda = 0.01, iterations = 3000, train accuracy = 0.7710437710437711, test accuracy = 0.8513189448441247\n",
      "Learning rate = 0.001, lambda = 0.01, iterations = 5000, train accuracy = 0.7912457912457912, test accuracy = 0.8441247002398081\n",
      "Learning rate = 0.001, lambda = 0.01, iterations = 10000, train accuracy = 0.7822671156004489, test accuracy = 0.86810551558753\n",
      "Learning rate = 0.001, lambda = 0.01, iterations = 15000, train accuracy = 0.7699214365881033, test accuracy = 0.8441247002398081\n",
      "Learning rate = 0.0001, lambda = 0.01, iterations = 5000, train accuracy = 0.7946127946127947, test accuracy = 0.9424460431654677\n",
      "Learning rate = 0.0001, lambda = 0.01, iterations = 10000, train accuracy = 0.7946127946127947, test accuracy = 0.9256594724220624\n",
      "Learning rate = 0.0001, lambda = 0.01, iterations = 15000, train accuracy = 0.792368125701459, test accuracy = 0.9448441247002398\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = [\n",
    "(0.01, 0.01, 2000),\n",
    "(0.01, 0.01, 5000),\n",
    "(0.001, 0.01, 1000),\n",
    "(0.001, 0.01, 3000),\n",
    "(0.001, 0.01, 5000),\n",
    "(0.001, 0.01, 10000),\n",
    "(0.001, 0.01, 15000),\n",
    "(0.0001, 0.01, 5000),\n",
    "(0.0001, 0.01, 10000),\n",
    "(0.0001, 0.01, 15000),\n",
    "]\n",
    "\n",
    "for h in hyperparameters:\n",
    "    lr, lambda_param, iters = h\n",
    "    my_svm = my_SVM(learning_rate=lr, lambda_param=lambda_param, n_iters=iters)\n",
    "    my_svm.fit(X_train, Y_train)\n",
    "    print(f'Learning rate = {lr}, lambda = {lambda_param}, iterations = {iters}, train accuracy = {np.mean(Y_train == my_svm.predict(X_train))}, test accuracy = {np.mean(Y_test == my_svm.predict(X_test))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим модель с параметрами (0.0001, 0.01, 5000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_svm = my_SVM(learning_rate=0.0001, lambda_param=0.01, n_iters=5000)\n",
    "my_svm.fit(X_train, Y_train)\n",
    "Y_pred = my_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_1</th>\n",
       "      <th>actual_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted_1</th>\n",
       "      <td>138</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_0</th>\n",
       "      <td>14</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual_1  actual_0\n",
       "predicted_1       138        10\n",
       "predicted_0        14       255"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9424460431654677\n",
      "Precision: 0.9324324324324325\n",
      "Recall: 0.9078947368421053\n"
     ]
    }
   ],
   "source": [
    "metrics_my_svm = metrics(confusion_matrix(Y_pred, Y_test))\n",
    "print(f'Accuracy: {metrics_my_svm[0]}\\nPrecision: {metrics_my_svm[1]}\\nRecall: {metrics_my_svm[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на модель SVM из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_svm_model = SVC()\n",
    "sklearn_svm_model.fit(X_train, Y_train)\n",
    "Y_pred = sklearn_svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_1</th>\n",
       "      <th>actual_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted_1</th>\n",
       "      <td>41</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_0</th>\n",
       "      <td>111</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual_1  actual_0\n",
       "predicted_1        41        36\n",
       "predicted_0       111       229"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6474820143884892\n",
      "Precision: 0.5324675324675324\n",
      "Recall: 0.26973684210526316\n"
     ]
    }
   ],
   "source": [
    "metrics_sklearn_svm = metrics(confusion_matrix(Y_pred, Y_test))\n",
    "print(f'Accuracy: {metrics_sklearn_svm[0]}\\nPrecision: {metrics_sklearn_svm[1]}\\nRecall: {metrics_sklearn_svm[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_1</th>\n",
       "      <th>actual_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted_1</th>\n",
       "      <td>113</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_0</th>\n",
       "      <td>39</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual_1  actual_0\n",
       "predicted_1       113         8\n",
       "predicted_0        39       257"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# С нормализацией данных по столбцам\n",
    "X_train_normalized = np.apply_along_axis(lambda x: (x-x.mean())/ x.std(), 0, X_train)\n",
    "X_test_normalized = np.apply_along_axis(lambda x: (x-x.mean())/ x.std(), 0, X_test)\n",
    "\n",
    "sklearn_svm_model = SVC()\n",
    "sklearn_svm_model.fit(X_train_normalized, Y_train)\n",
    "Y_pred = sklearn_svm_model.predict(X_test_normalized)\n",
    "confusion_matrix(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8872901678657075\n",
      "Precision: 0.9338842975206612\n",
      "Recall: 0.743421052631579\n"
     ]
    }
   ],
   "source": [
    "metrics_sklearn_svm = metrics(confusion_matrix(Y_pred, Y_test))\n",
    "print(f'Accuracy: {metrics_sklearn_svm[0]}\\nPrecision: {metrics_sklearn_svm[1]}\\nRecall: {metrics_sklearn_svm[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что нормализация данных сильно улучшила качество классификации. Подберем гиперпараметры с помощью RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'rbf', 'gamma': 0.1, 'C': 1}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def svc_param_selection(X, y):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    kernels = ['linear', 'rbf']\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas, 'kernel': kernels}\n",
    "    search = RandomizedSearchCV(SVC(), param_grid)\n",
    "    search.fit(X, y)\n",
    "    search.best_params_\n",
    "    return search.best_params_\n",
    "\n",
    "svc_param_selection(X_train_normalized, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_svm_model = SVC(kernel='rbf', gamma=0.01, C=100)\n",
    "sklearn_svm_model.fit(X_train_normalized, Y_train)\n",
    "Y_pred = sklearn_svm_model.predict(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_1</th>\n",
       "      <th>actual_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted_1</th>\n",
       "      <td>134</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_0</th>\n",
       "      <td>18</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual_1  actual_0\n",
       "predicted_1       134         3\n",
       "predicted_0        18       262"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9496402877697842\n",
      "Precision: 0.9781021897810219\n",
      "Recall: 0.881578947368421\n"
     ]
    }
   ],
   "source": [
    "metrics_sklearn_svm = metrics(confusion_matrix(Y_pred, Y_test))\n",
    "print(f'Accuracy: {metrics_sklearn_svm[0]}\\nPrecision: {metrics_sklearn_svm[1]}\\nRecall: {metrics_sklearn_svm[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполняемой мною лабораторной работы мной были изучены и составлены 4 предложенных классификатора. Logistic Regression, SVM, KNN, Naive Bayes. С помощью их удалось добиться хороших результатов. Все результаты больше 85%. Во время выполнения работы также использовал метод GridSearchCV, для определения лучших параметров и использовании кросс-валидации. В результате чего, удалось добиться еще более лучших результатов даже 95%.\n",
    "\n",
    "Для меня задание оказалось очень сложным."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML_lab_1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "b8f2a64b4d874d86bac9a28df61c451282f1015b12be6fd8db703c9049d6db33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
